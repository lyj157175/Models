{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicModel, self).__init__()\n",
    "        self.model_name = str(type(self))\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "    \n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "    \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    def __init__(self):\n",
    "        self.embedding_pretrained = None # 是否使用预训练的词向量\n",
    "        self.n_vocab = 100 # 词表中单词的个数\n",
    "        self.embed_size = 300 # 词向量的维度 \n",
    "        self.cuda = False # 是否使用gpu\n",
    "        self.filter_num = 100 # 每种尺寸卷积核的个数\n",
    "        self.filters = [3,4,5] # 卷积核的尺寸\n",
    "        self.label_num = 2 # 标签个数\n",
    "        self.dropout = 0.5 # dropout的概率\n",
    "        self.sentence_max_size = 50 #最大句子长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(BasicModel):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(TextCNN, self).__init__()\n",
    "        # 嵌入层\n",
    "        if config.embedding_pretrained is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(config.embedding_pretrained, freeze=False)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(config.n_vocab, config.embed_size) # batchsize*l\n",
    "        # 卷积层\n",
    "        self.conv1d_1 = nn.Conv1d(config.embed_size, config.filter_num, config.filters[0])  \n",
    "        self.conv1d_2 = nn.Conv1d(config.embed_size, config.filter_num, config.filters[1])\n",
    "        self.conv1d_3 = nn.Conv1d(config.embed_size, config.filter_num, config.filters[2])\n",
    "        # 池化层\n",
    "        self.Max_pool_1 = nn.MaxPool1d(config.sentence_max_size-3+1)\n",
    "        self.Max_pool_2 = nn.MaxPool1d(config.sentence_max_size-4+1)\n",
    "        self.Max_pool_3 = nn.MaxPool1d(config.sentence_max_size-5+1)\n",
    "        # Dropout层\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        #分类层\n",
    "        self.fc = nn.Linear(config.filter_num*len(config.filters), config.label_num)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        out = self.embedding(x) # bs *length*embedding_size\n",
    "        out = out.transpose(1, 2).contiguous() # bs*embedding_size*length,用最后一个维度来卷积\n",
    "        \n",
    "        x1 = F.relu(self.conv1d_1(out))   # b, filter_num, length-f+2p/s + 1\n",
    "        x2 = F.relu(self.conv1d_2(out))   # b, filter_num, length-f+2P/s + 1\n",
    "        x3 = F.relu(self.conv1d_3(out))   # b, filter_num, length-f+2p/s + 1\n",
    "        x1 = self.Max_pool_1(x1).squeeze()  # b, filter_num\n",
    "        x2 = self.Max_pool_2(x2).squeeze()  # b, filter_num\n",
    "        x3 = self.Max_pool_3(x3).squeeze()  # b, filter_num\n",
    "        \n",
    "        out = torch.cat([x1,x2,x3], 1)   # b, filter*3\n",
    "        out = self.dropout(out)  \n",
    "        out = self.fc(out)   # b, label_num\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondac1ed852f726f46e99aa9eda212d43d36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
