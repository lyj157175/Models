data: './data/save_data/'
logF: 'experiments/'
epoch: 20
batch_size: 64
optim: 'adam'
cell: 'lstm'
attention: 'luong_gate'
learning_rate: 0.0003
max_grad_norm: 10
learning_rate_decay: 0.5
start_decay_at: 2
emb_size: 512
hidden_size: 512
dec_num_layers: 3
enc_num_layers: 3
bidirectional: True
dropout: 0.1
max_time_step: 30
eval_interval: 100
save_interval: 5000
unk: False
schedule: False
schesamp: False
length_norm: True
metrics: ['micro_f1']
shared_vocab: False
beam_size: 1
eval_time: 10
mask: True
global_emb: False
tau: 0.1